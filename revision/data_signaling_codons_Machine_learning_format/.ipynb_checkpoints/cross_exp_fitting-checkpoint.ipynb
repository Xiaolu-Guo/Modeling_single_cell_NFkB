{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check xgboost version\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cross_val_predict(model, kfold, X, y ) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    no_classes = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.empty([0], dtype=int)\n",
    "    actual_X_val = np.empty([0], dtype=int)\n",
    "    predicted_classes = np.empty([0], dtype=int)\n",
    "    predicted_proba = np.empty([0, no_classes]) \n",
    "\n",
    "    for train_ndx, test_ndx in kfold.split(X):\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "        actual_X_val = np.append(actual_X_val,test_X)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "        except:\n",
    "            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)\n",
    "\n",
    "    return actual_classes, predicted_classes, predicted_proba, actual_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_classes, predicted_classes, sorted_labels):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "56 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.45098957        nan 0.45594407        nan        nan 0.45098926\n",
      "        nan 0.44798275 0.44992856 0.44851404 0.3961425  0.45205199\n",
      " 0.44939837 0.39384146        nan        nan 0.39649429        nan\n",
      " 0.39437149 0.44975063        nan        nan 0.44745147        nan\n",
      "        nan 0.45293647 0.45010555        nan 0.44992794        nan\n",
      " 0.44904251 0.39897311        nan 0.45222773        nan        nan\n",
      " 0.44886599 0.44320603        nan 0.45417306        nan        nan\n",
      " 0.39950549 0.45081352        nan 0.4359508  0.4536435         nan\n",
      " 0.4580664         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "[[101   1   0   4   2   1   0   1   1  10   0   0   8   0   7]\n",
      " [  2 140  33   1   1   0   0   1   1   7   1   0   1   6  44]\n",
      " [  1  41 148   0   0   0   0   0   0   0   3   0   0   2  14]\n",
      " [  5   3   0  21  11   3  10   9   8  42   9   9   8  17   4]\n",
      " [  2   0   0  14  32  47   2  21  10  22   8   6   8  52   6]\n",
      " [  1   1   0   4  14 163   3  19  22  11   9  14   4 135  12]\n",
      " [  2   3   0  10  10  17  25  29  11  52   9  11  39  20   1]\n",
      " [  7   0   0   3  15  57  18  62  32  42   5  22  27  51  25]\n",
      " [  4   2   0   8  14  46   4  41  51  15  11   7   7  38  43]\n",
      " [  5   6   0   5   2   3   7   4   3 389  80  74  61  19   2]\n",
      " [  0   2   1   4   3  12   7   7   3 108 208 124  18  24   0]\n",
      " [  2   3   1   5   3  10   3   9   2  81 149 207  38  33   2]\n",
      " [  9   0   0   9   5   1  12  10   0  98  17  40 269   6   3]\n",
      " [ 11   3   1   3  13  93   0   8  14  20  10  24  14 321  52]\n",
      " [  3  19   0   0   2  16   1  12  16  10   0   5   3  38 452]]\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.36465122        nan 0.36288037        nan        nan 0.35774794\n",
      "        nan 0.35898625 0.36429333 0.34571661 0.34996268 0.36464793\n",
      " 0.35385476 0.34978631        nan        nan 0.34766336        nan\n",
      " 0.35031791 0.36659452        nan        nan 0.36712847        nan\n",
      "        nan 0.36199432 0.35473909        nan 0.36606574        nan\n",
      " 0.3680103  0.35226215        nan 0.3657091         nan        nan\n",
      " 0.3443024  0.34890261        nan 0.36376611        nan        nan\n",
      " 0.35120068 0.35173118        nan 0.33810928 0.35650869        nan\n",
      " 0.36181764        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ade\n",
      "[[ 84   0   1   6   0   0   0   0   3  32   0   0   8   1   1]\n",
      " [  1  63  66   0   1   0   0   0   1  24   8   6   1   4  63]\n",
      " [  1  54  89   0   0   0   0   0   0  18   5   2   3   1  36]\n",
      " [  6   0   0  14  10   6   1   1   7  50   6   6  11  36   5]\n",
      " [  7   0   0   5  45  45   0  10   5  20   9   4   7  71   2]\n",
      " [  3   0   0   4  21 112   0  16  12  20  11  11   5 175  22]\n",
      " [  8   1   0   4  10  18   3  19  10  55   5   3  54  46   3]\n",
      " [  3   0   1   4  19  45   1  48  18  44  14  16  34  91  28]\n",
      " [  3   3   2   6  18  45   1  22  27  23  15   9   7  73  37]\n",
      " [ 16   3   2   6   3   3   1   2   3 353  66  46 102  48   6]\n",
      " [  1   1   1   2   9   8   0   5   0 104 154 128  38  64   6]\n",
      " [  3   1   2   2  11  13   0   1   1  91 130 137  65  82   9]\n",
      " [ 11   2   0   3   1   0   0   1   0 151  26  54 187  40   3]\n",
      " [  8   3   2   4  15  68   1   7  10  47  24  18  16 321  43]\n",
      " [  1  22  12   3   2  11   0  10  14  11   0   1   3  44 443]]\n"
     ]
    }
   ],
   "source": [
    "# try cross validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1) \n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "data_name_vec = ['Fitting', 'Ade']\n",
    "for data_name in data_name_vec :\n",
    "    # data_name = 'Ade'\n",
    "    XFileName = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "    yFileName = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "    SaveFileName = 'All_dose_RandomForest_conf_mat_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "    X = read_csv(XFileName,header = None)\n",
    "    #print(X.shape)            \n",
    "    y = read_csv(yFileName,header = None)\n",
    "    #print(y.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "\n",
    "    # Ensure y is one-dimensional\n",
    "    if y_np.ndim > 1 and y_np.shape[1] == 1:\n",
    "        y_np = y_np.flatten()\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 250, 500, 750, 1000],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Set up the cross-validation strategy\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create the base model to tune\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    # Instantiate the random search model\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,  # Number of parameter settings that are sampled\n",
    "        cv=kfold,\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_np, y_np)\n",
    "\n",
    "    # Use the best estimator for predictions\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    actual_classes, predicted_classes, _, _ = cross_val_predict(best_model, kfold, X_np, y_np)\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "    confu_mat = confusion_matrix(actual_classes,predicted_classes)\n",
    "    np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "    print(data_name)\n",
    "    print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5652, 6)\n",
      "(5652, 1)\n",
      "1330     5\n",
      "2776     9\n",
      "4360    12\n",
      "1399     6\n",
      "3884    11\n",
      "        ..\n",
      "905      4\n",
      "5192    14\n",
      "3980    11\n",
      "235      1\n",
      "5157    14\n",
      "Name: 0, Length: 3786, dtype: int64\n",
      "(1866,)\n",
      "(5652, 6)\n",
      "(5652, 1)\n",
      "0.33815648445873525\n",
      "[[ 34   0   0   1   0   0   0   0   3   5   0   0   5   1   1]\n",
      " [  0  18  26   0   0   0   0   0   0   7   5   2   0   2  17]\n",
      " [  1  19  22   0   0   0   0   0   0   2   1   1   2   0  14]\n",
      " [  5   0   0   5   6   1   0   3   2   9   0   3   5   8   2]\n",
      " [  1   0   0   3  19  15   1   7   3   4   3   2   1  14   0]\n",
      " [  0   0   1   1   7  39   0  12   4   9   3   3   1  48   7]\n",
      " [  3   1   0   0   5  10   5  10   2  13   0   5  18  13   1]\n",
      " [  1   0   1   1   8  16   3  22   6  16  12   3   6  23  10]\n",
      " [  0   3   0   3   7  15   0  10   9   6   7   0   2  21  15]\n",
      " [  6   5   1   3   1   2   2   2   3  96  29  19  33  13   1]\n",
      " [  0   1   0   0   4   0   1   0   0  28  50  43  11  20   3]\n",
      " [  2   0   1   0   5   5   2   3   0  33  61  50  14  17   2]\n",
      " [  6   1   1   3   0   1   1   5   0  38  21  20  61   8   1]\n",
      " [  1   2   1   0   9  36   2  11   9   3   8  19   7  65  11]\n",
      " [  1   8   7   2   1   2   1   2   9   0   0   0   0  16 136]]\n"
     ]
    }
   ],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "# 'Fitting' 'Ade' 'Sampling'\n",
    "data_name = 'Ade'\n",
    "XFileName = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X = read_csv(XFileName,header = None)\n",
    "print(X.shape)            \n",
    "y = read_csv(yFileName,header = None)\n",
    "print(y.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "#print(y_train)\n",
    "#print(y)\n",
    "# define the model\n",
    "# define dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "y_train = y_train.iloc[:, 0]\n",
    "print(y_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# import fitting data:\n",
    "\n",
    "data_name_2 = 'Fitting'\n",
    "XFileName_2 = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName_2 = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName_2 = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_2 = read_csv(XFileName,header = None)\n",
    "print(X_2.shape)            \n",
    "y_2 = read_csv(yFileName,header = None)\n",
    "print(y_2.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.33, random_state=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "confu_mat = confusion_matrix(y_test,y_pred)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(confu_mat)\n",
    "\n",
    "#y_pred_2 = model.predict(X_2)\n",
    "\n",
    "#confu_mat = confusion_matrix(y_2,y_pred_2)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "#accuracy = model.score(X_2, y_2)\n",
    "#print(accuracy)\n",
    "#print(confu_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5652, 6)\n",
      "(5652, 1)\n",
      "1330     5\n",
      "2776     9\n",
      "4360    12\n",
      "1399     6\n",
      "3884    11\n",
      "        ..\n",
      "905      4\n",
      "5192    14\n",
      "3980    11\n",
      "235      1\n",
      "5157    14\n",
      "Name: 0, Length: 3786, dtype: int64\n",
      "(5652, 6)\n",
      "(5652, 1)\n",
      "0.42711682743837087\n",
      "[[ 37   0   0   2   0   0   1   0   0   3   0   0   3   1   3]\n",
      " [  0  47   9   1   1   0   0   1   0   2   1   0   1   2  12]\n",
      " [  0  17  39   0   0   0   0   0   0   0   2   0   0   0   4]\n",
      " [  1   1   0   7   4   0   1   2   3   9   2   5   2   9   3]\n",
      " [  0   0   0   6  14  17   4  11   4   6   2   2   0   6   1]\n",
      " [  0   0   0   1   6  51   3   8   9   8   4   5   2  33   5]\n",
      " [  0   0   0   6   2   8   6  10   6  18   2   3  17   5   3]\n",
      " [  1   0   0   1   9  19   6  19  11  12   5   8  13  17   7]\n",
      " [  1   0   0   0   4  16   5  12  19   6   4   2   1   9  19]\n",
      " [  3   2   0   6   1   4   4   2   2 100  36  28  24   3   1]\n",
      " [  0   0   0   2   3   0   5   0   2  29  65  44   4   7   0]\n",
      " [  1   1   0   1   3   2   4   4   2  38  57  65   8   7   2]\n",
      " [  6   0   0   4   3   0   4   2   3  36   3  15  90   0   1]\n",
      " [  1   0   0   0   4  32   4   3   9   7   4   7   3  96  14]\n",
      " [  0   5   2   0   2   6   0   2   7   3   0   0   1  15 142]]\n"
     ]
    }
   ],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "# 'Fitting' 'Ade' 'Sampling'\n",
    "data_name = 'Fitting'\n",
    "XFileName = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X = read_csv(XFileName,header = None)\n",
    "print(X.shape)            \n",
    "y = read_csv(yFileName,header = None)\n",
    "print(y.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "#print(y_train)\n",
    "#print(y)\n",
    "# define the model\n",
    "# define dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "y_train = y_train.iloc[:, 0]\n",
    "print(y_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# import fitting data:\n",
    "\n",
    "data_name_2 = 'Ade'\n",
    "XFileName_2 = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName_2 = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName_2 = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_2 = read_csv(XFileName,header = None)\n",
    "print(X_2.shape)            \n",
    "y_2 = read_csv(yFileName,header = None)\n",
    "print(y_2.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.33, random_state=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "confu_mat = confusion_matrix(y_test,y_pred)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(confu_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
