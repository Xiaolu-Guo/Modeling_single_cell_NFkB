{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check xgboost version\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cross_val_predict(model, kfold, X, y ) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    no_classes = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.empty([0], dtype=int)\n",
    "    actual_X_val = np.empty([0], dtype=int)\n",
    "    predicted_classes = np.empty([0], dtype=int)\n",
    "    predicted_proba = np.empty([0, no_classes]) \n",
    "\n",
    "    for train_ndx, test_ndx in kfold.split(X):\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "        actual_X_val = np.append(actual_X_val,test_X)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "        except:\n",
    "            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)\n",
    "\n",
    "    return actual_classes, predicted_classes, predicted_proba, actual_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_classes, predicted_classes, sorted_labels):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 6)\n",
      "(3000, 1)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "74 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94933333        nan 0.96              nan        nan 0.962\n",
      "        nan 0.96566667 0.95466667 0.97066667 0.90166667 0.961\n",
      " 0.97066667 0.89933333        nan        nan 0.899             nan\n",
      " 0.898      0.95433333        nan        nan 0.95033333        nan\n",
      "        nan 0.95       0.96366667        nan 0.94666667        nan\n",
      " 0.95133333 0.89966667        nan 0.954             nan        nan\n",
      " 0.96933333 0.97266667        nan 0.94966667        nan        nan\n",
      " 0.90033333 0.97133333        nan 0.97333333 0.97033333        nan\n",
      " 0.963             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT\n",
      "[[988   8   4]\n",
      " [ 22 948  30]\n",
      " [  3  13 984]]\n",
      "(3000, 6)\n",
      "(3000, 1)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "66 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "44 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.95733333        nan 0.96433333        nan        nan 0.965\n",
      "        nan 0.969      0.962      0.972      0.913      0.968\n",
      " 0.97166667 0.91566667        nan        nan 0.91366667        nan\n",
      " 0.916      0.96066667        nan        nan 0.95833333        nan\n",
      "        nan 0.958      0.96333333        nan 0.95633333        nan\n",
      " 0.95866667 0.91266667        nan 0.962             nan        nan\n",
      " 0.973      0.973             nan 0.95766667        nan        nan\n",
      " 0.91666667 0.97233333        nan 0.973      0.97233333        nan\n",
      " 0.966             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IkBamut\n",
      "[[977  18   5]\n",
      " [ 26 951  23]\n",
      " [  3   6 991]]\n"
     ]
    }
   ],
   "source": [
    "# try cross validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1) \n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "data_name_vec = ['WT', 'IkBamut']\n",
    "for data_name in data_name_vec :\n",
    "    file_names = 'SimIkBamutClass'\n",
    "    XFileName = file_names + '_X_codon_stim_' + data_name + '.csv'\n",
    "    yFileName = file_names + '_y_codon_stim_' + data_name + '.csv'\n",
    "    SaveFileName = file_names + '_RandomForest_conf_mat_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "    X = read_csv(XFileName,header = None)\n",
    "    #print(X.shape)            \n",
    "    y = read_csv(yFileName,header = None)\n",
    "    #print(y.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "\n",
    "    print(X_np.shape)\n",
    "    print(y_np.shape)\n",
    "    # Ensure y is one-dimensional\n",
    "    if y_np.ndim > 1 and y_np.shape[1] == 1:\n",
    "        y_np = y_np.flatten()\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 250, 500, 750, 1000],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Set up the cross-validation strategy\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create the base model to tune\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    # Instantiate the random search model\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,  # Number of parameter settings that are sampled\n",
    "        cv=kfold,\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_np, y_np)\n",
    "\n",
    "    # Use the best estimator for predictions\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    actual_classes, predicted_classes, _, _ = cross_val_predict(best_model, kfold, X_np, y_np)\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "    confu_mat = confusion_matrix(actual_classes,predicted_classes)\n",
    "    np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "    print(data_name)\n",
    "    print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 6)\n",
      "(3000, 1)\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "10 fits failed out of a total of 25.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.95933333 0.90133333        nan 0.89866667        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "(3000,)\n",
      "WT\n",
      "[[978  12  10]\n",
      " [ 31 919  50]\n",
      " [ 10   9 981]]\n",
      "(3000, 6)\n",
      "(3000, 1)\n",
      "IkBamut\n",
      "[[689 269  42]\n",
      " [  4 965  31]\n",
      " [  0  21 979]]\n"
     ]
    }
   ],
   "source": [
    "# try cross validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1) \n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "data_name_vec = ['WT']\n",
    "for data_name in data_name_vec :\n",
    "    file_names = 'SimIkBamutClass'\n",
    "    XFileName = file_names + '_X_codon_stim_' + data_name + '.csv'\n",
    "    yFileName = file_names + '_y_codon_stim_' + data_name + '.csv'\n",
    "    SaveFileName = file_names + '_RandomForest_conf_mat_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "    X = read_csv(XFileName,header = None)\n",
    "    #print(X.shape)            \n",
    "    y = read_csv(yFileName,header = None)\n",
    "    #print(y.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "\n",
    "    print(X_np.shape)\n",
    "    print(y_np.shape)\n",
    "    # Ensure y is one-dimensional\n",
    "    if y_np.ndim > 1 and y_np.shape[1] == 1:\n",
    "        y_np = y_np.flatten()\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 250, 500, 750, 1000],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Set up the cross-validation strategy\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create the base model to tune\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    # Instantiate the random search model\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=5,  # Number of parameter settings that are sampled\n",
    "        cv=kfold,\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_np, y_np)\n",
    "\n",
    "    # Use the best estimator for predictions\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    actual_classes, predicted_classes, _, _ = cross_val_predict(best_model, kfold, X_np, y_np)\n",
    "    # predicted_classes = best_model.predict(X_np)\n",
    "    # actual_classes = y_np\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "    print(actual_classes.shape)\n",
    "    print(predicted_classes.shape)\n",
    "    confu_mat = confusion_matrix(actual_classes,predicted_classes)\n",
    "    # np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "    print(data_name)\n",
    "    print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "XFileName_IkBamut = file_names + '_X_codon_stim_' + 'IkBamut' + '.csv'\n",
    "yFileName_IkBamut = file_names + '_y_codon_stim_' + 'IkBamut' + '.csv'\n",
    "SaveFileName_IkBamut = file_names + '_RandomForest_conf_mat_' + 'WT_Train_IkBamut' + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_IkBamut = read_csv(XFileName_IkBamut,header = None)\n",
    "print(X_IkBamut.shape)            \n",
    "y_IkBamut = read_csv(yFileName_IkBamut,header = None)\n",
    "print(y_IkBamut.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "X_np_IkBamut = X_IkBamut.to_numpy()\n",
    "y_np_IkBamut = y_IkBamut.to_numpy()\n",
    "\n",
    "    # Ensure y is one-dimensional\n",
    "if y_np_IkBamut.ndim > 1 and y_np_IkBamut.shape[1] == 1:\n",
    "    y_np_IkBamut = y_np_IkBamut.flatten()\n",
    "\n",
    "y_pred_IkBamut = best_model.predict(X_np_IkBamut)\n",
    "    # Evaluate using cross-validation\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "confu_mat = confusion_matrix(y_np_IkBamut,y_pred_IkBamut)\n",
    "np.savetxt(SaveFileName_IkBamut,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "print('IkBamut')\n",
    "print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
