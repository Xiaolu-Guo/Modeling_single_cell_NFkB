{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check xgboost version\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cross_val_predict(model, kfold, X, y ) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    no_classes = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.empty([0], dtype=int)\n",
    "    actual_X_val = np.empty([0], dtype=int)\n",
    "    predicted_classes = np.empty([0], dtype=int)\n",
    "    predicted_proba = np.empty([0, no_classes]) \n",
    "\n",
    "    for train_ndx, test_ndx in kfold.split(X):\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "        actual_X_val = np.append(actual_X_val,test_X)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "        except:\n",
    "            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)\n",
    "\n",
    "    return actual_classes, predicted_classes, predicted_proba, actual_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_classes, predicted_classes, sorted_labels):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.44568312        nan 0.45523579        nan        nan 0.44922185\n",
      "        nan 0.45098894 0.44798291 0.44851357 0.39844307 0.45205371\n",
      " 0.44692096 0.3929576         nan        nan 0.39649633        nan\n",
      " 0.39242584 0.44179198        nan        nan 0.44992809        nan\n",
      "        nan 0.44957552 0.44691987        nan 0.44656667        nan\n",
      " 0.4472751  0.39791179        nan 0.44763018        nan        nan\n",
      " 0.44515137 0.44497578        nan 0.45028176        nan        nan\n",
      " 0.39844245 0.44904455        nan 0.43860833 0.45399779        nan\n",
      " 0.45523751        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "[[102   1   1  10   3   6   0   0   0   3   0   0  10   0   0]\n",
      " [  1 135  37   0   6  44   0   1   1   1   1   0   9   1   1]\n",
      " [  1  44 146   0   2  14   0   0   0   0   0   0   1   1   0]\n",
      " [ 12   2   0 269   7   4   7  10   0   9   7   1  97  17  37]\n",
      " [ 10   4   1  16 318  55   0   9  17   3  12  94  18   9  21]\n",
      " [  2  13   4   5  40 454   1  11  16   0   4  14   9   0   4]\n",
      " [  2   2   0  40  21   2  30  26  12  10   9  19  53   5   8]\n",
      " [  7   0   0  24  55  29  23  67  22   4  13  54  37  13  18]\n",
      " [  4   3   0   8  40  38   7  42  47   4  13  53  14   9   9]\n",
      " [  4   3   0  11  17   5   5   8   8  18  15   5  41  11   8]\n",
      " [  2   0   0   6  54   4   4  29  14  11  30  46  15   9   6]\n",
      " [  2   1   0   2 133  10   3  19  21   3  16 166  13  10  13]\n",
      " [  7   7   0  55  19   1   4   4   1   6   2   7 392  73  82]\n",
      " [  0   2   1  21  21   0   4   6   4   2   2  12 105 199 142]\n",
      " [  3   3   1  36  33   3   1   9   4   5   3   8  90 149 200]]\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "58 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "52 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.36181999        nan 0.36641785        nan        nan 0.35757173\n",
      "        nan 0.35845763 0.36358771 0.3575722  0.35261864 0.36040343\n",
      " 0.35597897 0.35137923        nan        nan 0.3524418         nan\n",
      " 0.35261848 0.36111202        nan        nan 0.36252795        nan\n",
      "        nan 0.35757283 0.35527257        nan 0.36765616        nan\n",
      " 0.37013435 0.35527163        nan 0.36270369        nan        nan\n",
      " 0.35598069 0.34836991        nan 0.35863383        nan        nan\n",
      " 0.35456429 0.35367918        nan 0.3434151  0.35845637        nan\n",
      " 0.36252748        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ade\n",
      "[[ 86   0   0   9   1   3   0   0   3   6   0   0  28   0   0]\n",
      " [  1  57  63   1   4  70   0   0   0   0   1   0  26   9   6]\n",
      " [  1  49  91   4   1  38   0   0   0   0   0   0  17   7   1]\n",
      " [ 11   2   1 185  43   3   1   1   0   2   1   1 157  31  40]\n",
      " [ 10   3   0  19 322  44   0   7   7   4  12  70  42  22  25]\n",
      " [  0  23  16   4  47 435   0  12  13   3   2   5  15   0   2]\n",
      " [  7   1   0  51  50   3   0  20   6   5  10  20  56   3   7]\n",
      " [  3   2   0  32  96  27   0  55  16   2  17  44  39  12  21]\n",
      " [  3   2   1   5  75  37   0  25  32   4  16  41  27  12  11]\n",
      " [  8   0   0  11  31   4   2   2   8  10  18   4  48   7   6]\n",
      " [  7   0   0   6  64   4   0  11   6   6  46  43  21  10   6]\n",
      " [  3   1   0   8 168  22   0  14  13   6  16 120  18  11  12]\n",
      " [ 17   5   3  86  46   6   0   1   3   6   3   3 366  56  59]\n",
      " [  1   1   1  31  56   5   0   4   1   1   9  15 107 164 125]\n",
      " [  4   1   1  59  82   8   0   1   0   3  10  15  97 144 123]]\n"
     ]
    }
   ],
   "source": [
    "# try cross validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1) \n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "data_name_vec = ['Fitting', 'Ade']\n",
    "for data_name in data_name_vec :\n",
    "    # data_name = 'Ade'\n",
    "    XFileName = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "    yFileName = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "    SaveFileName = 'All_dose_RandomForest_conf_mat_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "    X = read_csv(XFileName,header = None)\n",
    "    #print(X.shape)            \n",
    "    y = read_csv(yFileName,header = None)\n",
    "    #print(y.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "\n",
    "    # Ensure y is one-dimensional\n",
    "    if y_np.ndim > 1 and y_np.shape[1] == 1:\n",
    "        y_np = y_np.flatten()\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 250, 500, 750, 1000],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Set up the cross-validation strategy\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create the base model to tune\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    # Instantiate the random search model\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,  # Number of parameter settings that are sampled\n",
    "        cv=kfold,\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_np, y_np)\n",
    "\n",
    "    # Use the best estimator for predictions\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    actual_classes, predicted_classes, _, _ = cross_val_predict(best_model, kfold, X_np, y_np)\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "    confu_mat = confusion_matrix(actual_classes,predicted_classes)\n",
    "    np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "    print(data_name)\n",
    "    print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5652, 6)\n",
      "(5652, 1)\n",
      "1330     4\n",
      "2776     7\n",
      "4360    12\n",
      "1399     4\n",
      "3884    11\n",
      "        ..\n",
      "905      3\n",
      "5192    14\n",
      "3980    12\n",
      "235      1\n",
      "5157    14\n",
      "Name: 0, Length: 3786, dtype: int64\n",
      "(1866,)\n",
      "(5652, 6)\n",
      "(5652, 1)\n",
      "0.35101822079314043\n",
      "[[ 36   0   0   4   0   1   0   0   3   1   0   0   4   0   1]\n",
      " [  0  23  23   1   1  14   0   0   1   0   0   0   7   6   1]\n",
      " [  0  17  25   2   0  14   0   0   0   0   0   0   2   2   0]\n",
      " [  5   1   1  68  10   2   3   2   0   2   0   1  35   9  20]\n",
      " [  4   1   0  10  73  12   1   9   7   2   8  33  12   8  12]\n",
      " [  0   8  10   1  12 146   0   4   5   0   1   3   2   0   1]\n",
      " [  3   1   0  21  11   1   5  10   3   2   6   7  15   3   3]\n",
      " [  1   0   0  13  20  11   0  19   8   3   6  11  14   2   8]\n",
      " [  0   1   0   3  21  12   0  10   7   3   5  12   8   3   1]\n",
      " [  3   0   0   4  10   2   0   3   2   3   3   1  13   1   2]\n",
      " [  3   0   0   4  14   3   6   8   6   1  19  10   3   5   3]\n",
      " [  2   0   1   2  43   7   5  14   9   3  11  37   4   3   6]\n",
      " [ 11   2   3  42   7   1   3   2   2   6   1   3 107  21  13]\n",
      " [  1   0   0   9  13   1   1   4   3   3   2   3  30  47  43]\n",
      " [  2   0   0  23  21   2   2   4   1   2   2   4  23  51  40]]\n"
     ]
    }
   ],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "# 'Fitting' 'Ade' 'Sampling'\n",
    "data_name = 'Ade'\n",
    "XFileName = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X = read_csv(XFileName,header = None)\n",
    "print(X.shape)            \n",
    "y = read_csv(yFileName,header = None)\n",
    "print(y.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "#print(y_train)\n",
    "#print(y)\n",
    "# define the model\n",
    "# define dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "y_train = y_train.iloc[:, 0]\n",
    "print(y_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# import fitting data:\n",
    "\n",
    "data_name_2 = 'Fitting'\n",
    "XFileName_2 = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName_2 = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName_2 = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_2 = read_csv(XFileName,header = None)\n",
    "print(X_2.shape)            \n",
    "y_2 = read_csv(yFileName,header = None)\n",
    "print(y_2.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.33, random_state=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "confu_mat = confusion_matrix(y_test,y_pred)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(confu_mat)\n",
    "\n",
    "#y_pred_2 = model.predict(X_2)\n",
    "\n",
    "#confu_mat = confusion_matrix(y_2,y_pred_2)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "#accuracy = model.score(X_2, y_2)\n",
    "#print(accuracy)\n",
    "#print(confu_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5652, 6)\n",
      "(5652, 1)\n",
      "1330     5\n",
      "2776     9\n",
      "4360    12\n",
      "1399     6\n",
      "3884    11\n",
      "        ..\n",
      "905      4\n",
      "5192    14\n",
      "3980    11\n",
      "235      1\n",
      "5157    14\n",
      "Name: 0, Length: 3786, dtype: int64\n",
      "(5652, 6)\n",
      "(5652, 1)\n",
      "0.42711682743837087\n",
      "[[ 37   0   0   2   0   0   1   0   0   3   0   0   3   1   3]\n",
      " [  0  47   9   1   1   0   0   1   0   2   1   0   1   2  12]\n",
      " [  0  17  39   0   0   0   0   0   0   0   2   0   0   0   4]\n",
      " [  1   1   0   7   4   0   1   2   3   9   2   5   2   9   3]\n",
      " [  0   0   0   6  14  17   4  11   4   6   2   2   0   6   1]\n",
      " [  0   0   0   1   6  51   3   8   9   8   4   5   2  33   5]\n",
      " [  0   0   0   6   2   8   6  10   6  18   2   3  17   5   3]\n",
      " [  1   0   0   1   9  19   6  19  11  12   5   8  13  17   7]\n",
      " [  1   0   0   0   4  16   5  12  19   6   4   2   1   9  19]\n",
      " [  3   2   0   6   1   4   4   2   2 100  36  28  24   3   1]\n",
      " [  0   0   0   2   3   0   5   0   2  29  65  44   4   7   0]\n",
      " [  1   1   0   1   3   2   4   4   2  38  57  65   8   7   2]\n",
      " [  6   0   0   4   3   0   4   2   3  36   3  15  90   0   1]\n",
      " [  1   0   0   0   4  32   4   3   9   7   4   7   3  96  14]\n",
      " [  0   5   2   0   2   6   0   2   7   3   0   0   1  15 142]]\n"
     ]
    }
   ],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "# 'Fitting' 'Ade' 'Sampling'\n",
    "data_name = 'Fitting'\n",
    "XFileName = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X = read_csv(XFileName,header = None)\n",
    "print(X.shape)            \n",
    "y = read_csv(yFileName,header = None)\n",
    "print(y.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "#print(y_train)\n",
    "#print(y)\n",
    "# define the model\n",
    "# define dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "y_train = y_train.iloc[:, 0]\n",
    "print(y_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# import fitting data:\n",
    "\n",
    "data_name_2 = 'Ade'\n",
    "XFileName_2 = 'All_dose_X_codon_stim_' + data_name + '.csv'\n",
    "yFileName_2 = 'All_dose_y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName_2 = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_2 = read_csv(XFileName,header = None)\n",
    "print(X_2.shape)            \n",
    "y_2 = read_csv(yFileName,header = None)\n",
    "print(y_2.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.33, random_state=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "confu_mat = confusion_matrix(y_test,y_pred)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(confu_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
