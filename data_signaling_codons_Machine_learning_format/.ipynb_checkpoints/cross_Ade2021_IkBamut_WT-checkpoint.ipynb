{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check xgboost version\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cross_val_predict(model, kfold, X, y ) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    no_classes = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.empty([0], dtype=int)\n",
    "    actual_X_val = np.empty([0], dtype=int)\n",
    "    predicted_classes = np.empty([0], dtype=int)\n",
    "    predicted_proba = np.empty([0, no_classes]) \n",
    "\n",
    "    for train_ndx, test_ndx in kfold.split(X):\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "        actual_X_val = np.append(actual_X_val,test_X)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "        except:\n",
    "            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)\n",
    "\n",
    "    return actual_classes, predicted_classes, predicted_proba, actual_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_classes, predicted_classes, sorted_labels):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1774, 6)\n",
      "(1774, 1)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "47 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "63 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.86919869        nan 0.87202196        nan        nan 0.86469006\n",
      "        nan 0.87145381 0.86638179 0.8691971  0.86299674 0.86299674\n",
      " 0.87032546 0.8641235         nan        nan 0.8613066         nan\n",
      " 0.86299674 0.86525503        nan        nan 0.87032864        nan\n",
      "        nan 0.8708952  0.86750537        nan 0.87145699        nan\n",
      " 0.86807512 0.86243336        nan 0.86751015        nan        nan\n",
      " 0.8641235  0.86017188        nan 0.87089361        nan        nan\n",
      " 0.86412191 0.87088884        nan 0.86242699 0.86863531        nan\n",
      " 0.87145381        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT\n",
      "[[612  31  45]\n",
      " [ 18 529   5]\n",
      " [ 76  52 406]]\n",
      "(1738, 6)\n",
      "(1738, 1)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "38 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.78538706        nan 0.78883865        nan        nan 0.78423267\n",
      "        nan 0.78941005 0.79171553 0.78883865 0.78250522 0.78596674\n",
      " 0.78884196 0.78365961        nan        nan 0.78653483        nan\n",
      " 0.78538375 0.78710954        nan        nan 0.78653483        nan\n",
      "        nan 0.78078108 0.78653483        nan 0.78423432        nan\n",
      " 0.78998476 0.78078274        nan 0.79056776        nan        nan\n",
      " 0.78596012 0.77962834        nan 0.78481069        nan        nan\n",
      " 0.78538541 0.78883865        nan 0.77617675 0.79056941        nan\n",
      " 0.78826559        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IkBamut\n",
      "[[528  34  93]\n",
      " [  8 446  51]\n",
      " [ 96  80 402]]\n"
     ]
    }
   ],
   "source": [
    "# try cross validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1) \n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "data_name_vec = ['WT', 'IkBamut']\n",
    "for data_name in data_name_vec :\n",
    "    # data_name = 'Ade'\n",
    "    XFileName = 'Ade2021exp_X_codon_stim_' + data_name + '.csv'\n",
    "    yFileName = 'Ade2021exp_y_codon_stim_' + data_name + '.csv'\n",
    "    SaveFileName = 'Ade2021exp_RandomForest_conf_mat_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "    X = read_csv(XFileName,header = None)\n",
    "    #print(X.shape)            \n",
    "    y = read_csv(yFileName,header = None)\n",
    "    #print(y.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "\n",
    "    print(X_np.shape)\n",
    "    print(y_np.shape)\n",
    "    # Ensure y is one-dimensional\n",
    "    if y_np.ndim > 1 and y_np.shape[1] == 1:\n",
    "        y_np = y_np.flatten()\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 250, 500, 750, 1000],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Set up the cross-validation strategy\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create the base model to tune\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    # Instantiate the random search model\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,  # Number of parameter settings that are sampled\n",
    "        cv=kfold,\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_np, y_np)\n",
    "\n",
    "    # Use the best estimator for predictions\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    actual_classes, predicted_classes, _, _ = cross_val_predict(best_model, kfold, X_np, y_np)\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "    confu_mat = confusion_matrix(actual_classes,predicted_classes)\n",
    "    np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "    print(data_name)\n",
    "    print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1774, 6)\n",
      "(1774, 1)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "110 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "44 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "66 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.86919869        nan 0.87202196        nan        nan 0.86469006\n",
      "        nan 0.87145381 0.86638179 0.8691971  0.86299674 0.86299674\n",
      " 0.87032546 0.8641235         nan        nan 0.8613066         nan\n",
      " 0.86299674 0.86525503        nan        nan 0.87032864        nan\n",
      "        nan 0.8708952  0.86750537        nan 0.87145699        nan\n",
      " 0.86807512 0.86243336        nan 0.86751015        nan        nan\n",
      " 0.8641235  0.86017188        nan 0.87089361        nan        nan\n",
      " 0.86412191 0.87088884        nan 0.86242699 0.86863531        nan\n",
      " 0.87145381        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1774,)\n",
      "(1774,)\n",
      "WT\n",
      "[[612  31  45]\n",
      " [ 18 529   5]\n",
      " [ 76  52 406]]\n",
      "(1738, 6)\n",
      "(1738, 1)\n",
      "IkBamut\n",
      "[[618  33   4]\n",
      " [ 54 445   6]\n",
      " [393  92  93]]\n"
     ]
    }
   ],
   "source": [
    "# try cross validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1) \n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "data_name_vec = ['WT']\n",
    "for data_name in data_name_vec :\n",
    "    # data_name = 'Ade'\n",
    "    XFileName = 'Ade2021exp_X_codon_stim_' + data_name + '.csv'\n",
    "    yFileName = 'Ade2021exp_y_codon_stim_' + data_name + '.csv'\n",
    "    SaveFileName = 'Ade2021exp_RandomForest_conf_mat_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "    X = read_csv(XFileName,header = None)\n",
    "    #print(X.shape)            \n",
    "    y = read_csv(yFileName,header = None)\n",
    "    #print(y.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_np = X.to_numpy()\n",
    "    y_np = y.to_numpy()\n",
    "\n",
    "    print(X_np.shape)\n",
    "    print(y_np.shape)\n",
    "    # Ensure y is one-dimensional\n",
    "    if y_np.ndim > 1 and y_np.shape[1] == 1:\n",
    "        y_np = y_np.flatten()\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_dist = {\n",
    "        'n_estimators': [100, 250, 500, 750, 1000],\n",
    "        'max_depth': [None, 5, 10, 15, 20],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    # Set up the cross-validation strategy\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # Create the base model to tune\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "    # Instantiate the random search model\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=50,  # Number of parameter settings that are sampled\n",
    "        cv=kfold,\n",
    "        verbose=1,\n",
    "        random_state=1,\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "\n",
    "    # Fit the random search model\n",
    "    random_search.fit(X_np, y_np)\n",
    "\n",
    "    # Use the best estimator for predictions\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    actual_classes, predicted_classes, _, _ = cross_val_predict(best_model, kfold, X_np, y_np)\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "    print(actual_classes.shape)\n",
    "    print(predicted_classes.shape)\n",
    "    confu_mat = confusion_matrix(actual_classes,predicted_classes)\n",
    "    # np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "    print(data_name)\n",
    "    print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "XFileName_IkBamut = 'Ade2021exp_X_codon_stim_' + 'IkBamut' + '.csv'\n",
    "yFileName_IkBamut = 'Ade2021exp_y_codon_stim_' + 'IkBamut' + '.csv'\n",
    "SaveFileName_IkBamut = 'Ade2021exp_RandomForest_conf_mat_' + 'WT_Train_IkBamut' + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_IkBamut = read_csv(XFileName_IkBamut,header = None)\n",
    "print(X_IkBamut.shape)            \n",
    "y_IkBamut = read_csv(yFileName_IkBamut,header = None)\n",
    "print(y_IkBamut.shape)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "X_np_IkBamut = X_IkBamut.to_numpy()\n",
    "y_np_IkBamut = y_IkBamut.to_numpy()\n",
    "\n",
    "    # Ensure y is one-dimensional\n",
    "if y_np_IkBamut.ndim > 1 and y_np_IkBamut.shape[1] == 1:\n",
    "    y_np_IkBamut = y_np_IkBamut.flatten()\n",
    "\n",
    "y_pred_IkBamut = best_model.predict(X_np_IkBamut)\n",
    "    # Evaluate using cross-validation\n",
    "\n",
    "    #kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "    #model = RandomForestClassifier(random_state=1)\n",
    "    # actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "confu_mat = confusion_matrix(y_np_IkBamut,y_pred_IkBamut)\n",
    "np.savetxt(SaveFileName_IkBamut,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "\n",
    "print('IkBamut')\n",
    "print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
